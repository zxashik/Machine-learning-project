{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImdbLstm.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxashik/Machine-learning-project/blob/master/ImdbLstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyi2oqgPCKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4258lPYcCmv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLJ6vty_C5NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hx6dUrjGTbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
        {
      "cell_type": "code",
      "metadata": {
        "id": "6hx6dUrjGTbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        
        "Epoch 1/3 25000 /25000  [===========] - 277s 11ms/step - loss: 0.4384 - acc: 0.7861\n",
        "Epoch 2/3 25000 /25000  [==========]  - 274s 11ms/step - loss: 0.3004 - acc: 0.8800\n",
        "Epoch 3/3 25000 /25000  [==========]  - 285s 11ms/step - loss: 0.2622 - acc: 0.8968\n",
         "Accuracy : 86.65%"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
